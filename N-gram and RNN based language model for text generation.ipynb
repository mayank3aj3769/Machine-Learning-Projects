{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59380124",
   "metadata": {
    "id": "9a2591a0"
   },
   "source": [
    "## This project implements N-gram language modeling and RNN language modeling on text dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cdcbe1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "\n",
    "def print_line(*args):\n",
    "    \"\"\" Inline print and go to the begining of line\n",
    "    \"\"\"\n",
    "    args1 = [str(arg) for arg in args]\n",
    "    str_ = ' '.join(args1)\n",
    "    print('\\r' + str_, end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47eb3e49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1f8b239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.10.0\n",
      "Is GPU available? [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Check TensorFlow version and GPU availability\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"Is GPU available?\", tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10ba2708",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple, Union, Dict\n",
    "from collections import defaultdict\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe9572bb",
   "metadata": {
    "id": "6dca548c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of train sentences: 42068\n",
      "number of valid sentences: 3370\n",
      "number of test sentences: 3165\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "\n",
    "data_path = './datasets/a3-data'\n",
    "\n",
    "train_sentences = open(os.path.join(data_path, 'train.txt')).readlines()\n",
    "valid_sentences = open(os.path.join(data_path, 'valid.txt')).readlines()\n",
    "test_sentences = open(os.path.join(data_path, 'input.txt')).readlines()\n",
    "print('number of train sentences:', len(train_sentences))\n",
    "print('number of valid sentences:', len(valid_sentences))\n",
    "print('number of test sentences:', len(test_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d251558",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "class Preprocessor:\n",
    "    def __init__(self, punctuation=True, url=True, number=True):\n",
    "        self.punctuation = punctuation\n",
    "        self.url = url\n",
    "        self.number = number\n",
    "\n",
    "    def apply(self, sentence: str) -> str:\n",
    "        \"\"\" Apply the preprocessing rules to the sentence\n",
    "        Args:\n",
    "            sentence: raw sentence\n",
    "        Returns:\n",
    "            sentence: clean sentence\n",
    "        \"\"\"\n",
    "        sentence = sentence.lower()\n",
    "        sentence = sentence.replace('<unk>', '')\n",
    "        if self.url:\n",
    "            sentence = Preprocessor.remove_url(sentence)\n",
    "        if self.punctuation:\n",
    "            sentence = Preprocessor.remove_punctuation(sentence)\n",
    "        if self.number:\n",
    "            sentence = Preprocessor.remove_number(sentence)\n",
    "        sentence = re.sub(r'\\s+', ' ', sentence)\n",
    "        return sentence\n",
    "\n",
    "    @staticmethod\n",
    "    def remove_punctuation(sentence: str) -> str:\n",
    "        \"\"\" Remove punctuations in sentence with re\n",
    "        Args:\n",
    "            sentence: sentence with possible punctuations\n",
    "        Returns:\n",
    "            sentence: sentence without punctuations\n",
    "        \"\"\"\n",
    "        sentence = re.sub(r'[^\\w\\s]', ' ', sentence)\n",
    "        return sentence\n",
    "\n",
    "    @staticmethod\n",
    "    def remove_url(sentence: str) -> str:\n",
    "        \"\"\" Remove urls in text with re\n",
    "        Args:\n",
    "            sentence: sentence with possible urls\n",
    "        Returns:\n",
    "            sentence: sentence without urls\n",
    "        \"\"\"\n",
    "        sentence = re.sub(r'(https|http)?://(\\w|\\.|/|\\?|=|&|%)*\\b', ' ', sentence)\n",
    "        return sentence\n",
    "\n",
    "    @staticmethod\n",
    "    def remove_number(sentence: str) -> str:\n",
    "        \"\"\" Remove numbers in sentence with re\n",
    "        Args:\n",
    "            sentence: sentence with possible numbers\n",
    "        Returns:\n",
    "            sentence: sentence without numbers\n",
    "        \"\"\"\n",
    "        sentence = re.sub(r'\\d+', ' ', sentence)\n",
    "        return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8baf0519",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tokenizer:\n",
    "    def __init__(self, sos_token='<s>', eos_token='</s>', pad_token='<pad>', unk_token='<unk>', mask_token='<mask>'):\n",
    "        # Special tokens.\n",
    "        self.sos_token = sos_token\n",
    "        self.eos_token = eos_token\n",
    "        self.pad_token = pad_token\n",
    "        self.unk_token = unk_token\n",
    "        self.mask_token = mask_token\n",
    "        \n",
    "        self.vocab = { sos_token: 0, eos_token: 1, pad_token: 2, unk_token: 3, mask_token: 4 }  # token -> id\n",
    "        self.inverse_vocab = { 0: sos_token, 1: eos_token, 2: pad_token, 3: unk_token, 4: mask_token }  # id -> token\n",
    "        self.token_occurrence = { sos_token: 0, eos_token: 0, pad_token: 0, unk_token: 0, mask_token: 0 }  # token -> occurrence\n",
    "        \n",
    "        self.preprocessor = Preprocessor()\n",
    "\n",
    "    @property\n",
    "    def sos_token_id(self):\n",
    "        \"\"\" Create a property method.\n",
    "            You can use self.sos_token_id or tokenizer.sos_token_id to get the id of the sos_token.\n",
    "        \"\"\"\n",
    "        return self.vocab[self.sos_token]\n",
    "\n",
    "    @property\n",
    "    def eos_token_id(self):\n",
    "        return self.vocab[self.eos_token]\n",
    "\n",
    "    @property\n",
    "    def pad_token_id(self):\n",
    "        return self.vocab[self.pad_token]\n",
    "\n",
    "    @property\n",
    "    def unk_token_id(self):\n",
    "        return self.vocab[self.unk_token]\n",
    "\n",
    "    @property\n",
    "    def mask_token_id(self):\n",
    "        return self.vocab[self.mask_token]\n",
    "        \n",
    "    def __len__(self):\n",
    "        \"\"\" A magic method that enable program to know the number of tokens by calling:\n",
    "            ```python\n",
    "            tokenizer = Tokenizer()\n",
    "            num_tokens = len(tokenizer)\n",
    "            ```\n",
    "        \"\"\"\n",
    "        return len(self.vocab)\n",
    "        \n",
    "    def fit(self, sentences: List[str]):\n",
    "        \"\"\" Fit the tokenizer using all sentences.\n",
    "        Args:\n",
    "            sentences: All sentences in the dataset.\n",
    "        \"\"\"\n",
    "        n = len(sentences)\n",
    "        for i, sentence in enumerate(sentences):\n",
    "            if i % 100 == 0 or i == n - 1:\n",
    "                print_line('Fitting Tokenizer:', (i + 1), '/', n)\n",
    "            tokens = self.preprocessor.apply(sentence.strip()).split()\n",
    "            if len(tokens) <= 1:\n",
    "                continue\n",
    "            for token in tokens:\n",
    "                if token == '<unk>':\n",
    "                    continue\n",
    "                self.token_occurrence[token] = self.token_occurrence.get(token, 0) + 1\n",
    "        print_line('\\n')\n",
    "\n",
    "        token_occurrence = sorted(self.token_occurrence.items(), key=lambda e: e[1], reverse=True)\n",
    "        for token, occurrence in token_occurrence[:-5]:\n",
    "            token_id = len(self.vocab)\n",
    "            self.vocab[token] = token_id\n",
    "            self.inverse_vocab[token_id] = token\n",
    "\n",
    "        print('The number of distinct tokens:', len(self.vocab))\n",
    "        \n",
    "    def encode(self, sentences: List[str]) -> List[List[int]]:\n",
    "        \"\"\" Encode the sentences into token ids\n",
    "        Args:\n",
    "            sentences: Raw sentences\n",
    "        Returns:\n",
    "            sent_token_ids: A list of id list\n",
    "        \"\"\"\n",
    "        n = len(sentences)\n",
    "        sent_token_ids = []\n",
    "        for i, sentence in enumerate(sentences):\n",
    "            if i % 100 == 0 or i == n - 1:\n",
    "                print_line('Encoding with Tokenizer:', (i + 1), '/', n)\n",
    "            token_ids = []\n",
    "            tokens = self.preprocessor.apply(sentence.strip()).split()\n",
    "            for token in tokens:\n",
    "                if token == '<unk>':\n",
    "                    continue\n",
    "                if token in self.vocab:\n",
    "                    token_ids.append(self.vocab[token])\n",
    "            if len(token_ids) <= 1:\n",
    "                continue\n",
    "            token_ids = [self.sos_token_id] + token_ids + [self.eos_token_id]\n",
    "            sent_token_ids.append(token_ids)\n",
    "        print_line('\\n')\n",
    "        return sent_token_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "616aa40f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting Tokenizer: 2 / 2\n",
      "The number of distinct tokens: 44\n",
      "\n",
      "n : 2\n",
      "aer : 1\n",
      "banknote : 1\n",
      "berlitz : 1\n",
      "calloway : 1\n",
      "centrust : 1\n",
      "cluett : 1\n",
      "fromstein : 1\n",
      "gitano : 1\n",
      "guterman : 1\n",
      "\n",
      "Encoding with Tokenizer: 2 / 2\n",
      "\n",
      " aer banknote berlitz calloway centrust cluett fromstein gitano guterman hydro-quebec ipo kia memotec mlx nahb punts rake regatta rubens sim snack-food ssangyong swapo wachter \n",
      " ['<s>', 'aer', 'banknote', 'berlitz', 'calloway', 'centrust', 'cluett', 'fromstein', 'gitano', 'guterman', 'hydro', 'quebec', 'ipo', 'kia', 'memotec', 'mlx', 'nahb', 'punts', 'rake', 'regatta', 'rubens', 'sim', 'snack', 'food', 'ssangyong', 'swapo', 'wachter', '</s>'] \n",
      "\n",
      " pierre <unk> N years old will join the board as a nonexecutive director nov. N \n",
      " ['<s>', 'pierre', 'n', 'years', 'old', 'will', 'join', 'the', 'board', 'as', 'a', 'nonexecutive', 'director', 'nov', 'n', '</s>'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit(train_sentences[:2])\n",
    "print()\n",
    "\n",
    "token_occurrence = sorted(tokenizer.token_occurrence.items(), key=lambda e: e[1], reverse=True)\n",
    "for token, occurrence in token_occurrence[:10]:\n",
    "    print(token, ':', occurrence)\n",
    "print()\n",
    "sent_token_ids = tokenizer.encode(train_sentences[:2])\n",
    "print()\n",
    "for original_sentence, token_ids in zip(train_sentences[:2], sent_token_ids):\n",
    "    sentence = [tokenizer.inverse_vocab[token] for token in token_ids]\n",
    "    print(original_sentence, sentence, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cbe17f26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting Tokenizer: 42068 / 42068\n",
      "The number of distinct tokens: 9614\n",
      "Encoding with Tokenizer: 42068 / 42068\n",
      "Encoding with Tokenizer: 3370 / 3370\n",
      "Encoding with Tokenizer: 3165 / 3165\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit(train_sentences)\n",
    "train_token_ids = tokenizer.encode(train_sentences)\n",
    "valid_token_ids = tokenizer.encode(valid_sentences)\n",
    "test_token_ids = tokenizer.encode(test_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f9a0117a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unigram_count(train_token_ids: List[List[int]]) -> Dict:\n",
    "    \"\"\" Calculate the occurrence of each token in the dataset.\n",
    "    \n",
    "    Args:\n",
    "        train_token_ids: each element is a list of token ids\n",
    "    Return:\n",
    "        unigram_count: A map from token_id to occurrence\n",
    "    \"\"\"\n",
    "    unigram_count = {}\n",
    "    for i in range(len(train_token_ids)):\n",
    "        for j in range(len(train_token_ids[i])):\n",
    "            if unigram_count.get(train_token_ids[i][j],-1)==-1:\n",
    "                unigram_count[train_token_ids[i][j]]=1\n",
    "            else:\n",
    "                unigram_count[train_token_ids[i][j]]+=1\n",
    "    return unigram_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "57fc331a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bigram_count(train_token_ids: List[List[int]]) -> Dict[int, Dict]:\n",
    "    \"\"\" Calculate the occurrence of bigrams in the dataset.\n",
    "    \n",
    "    Args:\n",
    "        train_token_ids: each element is a list of token ids\n",
    "    Return:\n",
    "        bigram_count: A map from token_id to next token occurrence. Key: token_id, value: Dict[token_id -> occurrence]\n",
    "                      For example, {\n",
    "                          5: { 10: 5, 20: 4 }\n",
    "                      } means (5, 10) occurs 10 times, (5, 20) occurs 4 times.\n",
    "    \n",
    "                      (5,10)=5\n",
    "                      (5,20)=4\n",
    "                      5:{10:5,20:4}\n",
    "    \"\"\"\n",
    "    bigram_count = {}\n",
    "    pair_count={}\n",
    "    bigram_count = defaultdict(lambda: defaultdict(int))\n",
    "    for doc in train_token_ids:\n",
    "        for i in range(len(doc)-1):\n",
    "            if pair_count.get(tuple((doc[i],doc[i+1])),0)==0:\n",
    "                pair_count[tuple((doc[i],doc[i+1]))] = 1\n",
    "            else:\n",
    "                pair_count[tuple((doc[i],doc[i+1]))] += 1\n",
    "    \n",
    "    ls=list(pair_count.keys())\n",
    "    for i in range(len(ls)):\n",
    "        k,v=ls[i]\n",
    "        temp={v:pair_count[(k,v)]}\n",
    "        if bigram_count.get(k,{})=={}:\n",
    "            bigram_count[k]=temp\n",
    "        else:\n",
    "            temp1=bigram_count[k]\n",
    "            temp1[v]=pair_count[(k,v)]\n",
    "            bigram_count[k]=temp1\n",
    "    \n",
    "    return bigram_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9de779c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram_count = get_unigram_count(train_token_ids)\n",
    "bigram_count = get_bigram_count(train_token_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f70dcb38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69\n"
     ]
    }
   ],
   "source": [
    "print(len(bigram_count[672]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dfe61968",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiGram:\n",
    "    def __init__(self, unigram_count, bigram_count):\n",
    "        self.unigram_count = unigram_count\n",
    "        self.bigram_count = bigram_count\n",
    "        \n",
    "    def calc_prob(self, w1: int, w2: int) -> float:\n",
    "        \"\"\"\n",
    "        \n",
    "        Args:\n",
    "            w1, w2: current token and next token\n",
    "        Note:\n",
    "            if prob you calculated is 0, you should return 1e-5.\n",
    "        \"\"\"\n",
    "        count_w1 = self.unigram_count.get(w1, 0)\n",
    "        count_w1_w2 = self.bigram_count.get(w1, {}).get(w2, 0)\n",
    "    \n",
    "        if count_w1 == 0:\n",
    "            return 1e-5\n",
    "        else:\n",
    "            prob = count_w1_w2 / count_w1\n",
    "            if prob == 0:\n",
    "                return 1e-5\n",
    "        return prob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734adc0f",
   "metadata": {},
   "source": [
    "###  Good Turing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6d792232",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit\n",
    "\n",
    "\n",
    "def power_law(x, a, b):\n",
    "    \"\"\" Power law to fit the number of occurrence\n",
    "    \"\"\"\n",
    "    return a * np.power(x, b)\n",
    "\n",
    "\n",
    "class GoodTuring(BiGram):\n",
    "    def __init__(self, unigram_count, bigram_count, threshold=100):\n",
    "        super().__init__(unigram_count, bigram_count)\n",
    "        self.threshold = threshold\n",
    "        self.bigram_Nc = self.calc_Nc()\n",
    "        self.bi_c_star, self.bi_N = self.smoothing(self.bigram_Nc)\n",
    "        self.unigram_count=unigram_count\n",
    "\n",
    "    def calc_Nc(self) -> Dict[int, Union[float, int]]:\n",
    "        \"\"\" \n",
    "        \n",
    "        Return:\n",
    "            bigram_Nc: A map from count to the occurrence (count of count)\n",
    "                       For example {\n",
    "                           10: 78\n",
    "                       } means there are 78 bigrams occurs 10 times in the dataset.\n",
    "                       Also, 10 is a small c, for large c, it's occurrence will be replaced with the power law.\n",
    "        \"\"\"\n",
    "        # Count the occurrence of count in self.bigram_count.\n",
    "        bigram_Nc = defaultdict(int)\n",
    "        for counts in self.bigram_count.values():\n",
    "            for count in counts.values():\n",
    "                bigram_Nc[count] += 1\n",
    "\n",
    "        self.replace_large_c(bigram_Nc)\n",
    "        return bigram_Nc\n",
    "\n",
    "    def replace_large_c(self, Nc):\n",
    "        \"\"\" Fit with power law\n",
    "        \"\"\"\n",
    "        x, y = zip(*sorted(Nc.items(), reverse=True))\n",
    "        popt, pcov = curve_fit(power_law, x, y, bounds=([0, -np.inf], [np.inf, 0]))\n",
    "        a, b = popt\n",
    "\n",
    "        max_count = max(Nc.keys())\n",
    "        for c in range(self.threshold + 1, max_count + 2):\n",
    "            Nc[c] = power_law(c, a, b)\n",
    "\n",
    "    def smoothing(self, Nc: Dict[int, Union[float, int]]) -> Tuple[Dict[int, float], float]:\n",
    "        \"\"\" Calculate the c_star and N\n",
    "        \n",
    "        Args:\n",
    "            self.bigram_Nc\n",
    "        Returns:\n",
    "            c_star: The mapping from bigram count to smoothed count\n",
    "            N: The sum of c multiplied by Nc\n",
    "        \"\"\"\n",
    "        c_star = {}\n",
    "        N = 0\n",
    "        max_count = max(Nc.keys())\n",
    "        for count in range(1, max_count + 1):\n",
    "            if count not in Nc or count + 1 not in Nc:\n",
    "                continue\n",
    "            c_star[count] = (count + 1) * Nc[count + 1] / Nc[count]\n",
    "            N += count * Nc[count]\n",
    "        c_star[0] = Nc[1] / N\n",
    "        return c_star, N\n",
    "\n",
    "    def calc_prob(self, w1, w2):\n",
    "        \"\"\"         \n",
    "        Good-turing smoothening\n",
    "        Args:\n",
    "            w1, w2: current token and next token\n",
    "        \"\"\"\n",
    "        prob = 0\n",
    "        # Get the unigram count of w1\n",
    "        unigram_count_w1 = self.unigram_count.get(w1, 0)\n",
    "        # Get the smoothed bigram count of (w1, w2)\n",
    "        smoothed_bigram_count_w1_w2 = self.bi_c_star.get(self.bigram_count.get(w1, {}).get(w2, 0), 0)\n",
    "\n",
    "        if unigram_count_w1 == 0:\n",
    "            # w1 is not in the training data, so the probability is 0\n",
    "            prob = 0\n",
    "        else:\n",
    "            if smoothed_bigram_count_w1_w2 == 0:\n",
    "                # (w1, w2) is not in the training data, so use the unigram probability of w2\n",
    "                if self.unigram_count.get(w2,0)==0:\n",
    "                    self.unigram_count[w2]=1e-5\n",
    "                    prob = 1e-5/len(np.sum(self.unigram_count.values()))\n",
    "                else:\n",
    "                    prob = self.unigram_count[w2]/len(np.sum(self.unigram_count.values()))\n",
    "            else:\n",
    "                prob = smoothed_bigram_count_w1_w2 / unigram_count_w1\n",
    "\n",
    "        return prob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0b5804",
   "metadata": {},
   "source": [
    "###  Kneser-Ney smoothening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "48305eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KneserNey(BiGram):\n",
    "    def __init__(self, unigram_count, bigram_count, d=0.75):\n",
    "        super().__init__(unigram_count, bigram_count)\n",
    "        self.d = d\n",
    "        \n",
    "        self.lambda_ = self.calc_lambda()\n",
    "        self.p_continuation = self.calc_p_continuation()\n",
    "        \n",
    "    def calc_lambda(self):\n",
    "        \"\"\" \n",
    "        Return:\n",
    "            lambda_: A dict from token_id (w) to λ(w).\n",
    "        \"\"\"\n",
    "        lambda_ = {}\n",
    "        for w1 in self.unigram_count:\n",
    "            lambda_[w1] = self.d * len([w2 for w2 in self.bigram_count[w1] if self.bigram_count[w1][w2] > 0])\n",
    "            lambda_[w1] /= self.unigram_count[w1]\n",
    "        return lambda_\n",
    "    \n",
    "    def calc_p_continuation(self):\n",
    "        \"\"\" \n",
    "        Return:\n",
    "            lambda_: A dict from token_id (w) to λ(w).\n",
    "        \"\"\"\n",
    "        numerator = {}  # token -> type of previous token\n",
    "        denominator = len(self.bigram_count)  # type of all previous tokens\n",
    "        for w1 in self.bigram_count:\n",
    "            for w2 in self.bigram_count[w1]:\n",
    "                if self.bigram_count[w1][w2] > 0:\n",
    "                    numerator[w2] = numerator.get(w2, 0) + 1\n",
    "        p_continuation = { 0: 0, 2: 0, 3: 0, 4: 0 }\n",
    "        for w, count in numerator.items():\n",
    "            p_continuation[w] = count / denominator\n",
    "        return p_continuation\n",
    "    \n",
    "    def calc_prob(self, w1, w2):\n",
    "        \"\"\" Calculate the probability of p(w2 | w1) using the Kneser-Ney model.\n",
    "        \n",
    "        Args:\n",
    "            w1, w2: current token and next token\n",
    "        \"\"\"\n",
    "        c_w1_w2 = self.bigram_count[w1][w2] if w1 in self.bigram_count and w2 in self.bigram_count[w1] else 0\n",
    "        prob = max(c_w1_w2 - self.d, 0) / self.unigram_count[w1] + self.lambda_[w1] * self.p_continuation[w2]\n",
    "        \n",
    "        return prob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d915b8a",
   "metadata": {},
   "source": [
    "### Shows that perplexity is the exponential of the total loss divided by the number of predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a275b66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log2\n",
    "def perplexity(model, token_ids):\n",
    "    \"\"\" \n",
    "    Args:\n",
    "        model: the model you want to evaluate (BiGram, GoodTuring, or KneserNey)\n",
    "        token_ids: a list of validation token_ids\n",
    "    Return:\n",
    "        perplexity: the perplexity of the model on texts      \n",
    "    \"\"\"\n",
    "    log_probs = 0\n",
    "    n = len(token_ids)\n",
    "    n_words = 0\n",
    "    for i, tokens in enumerate(token_ids):\n",
    "        if i % 100 == 0 or i == n - 1:\n",
    "            print_line('Calculating perplexity:', (i + 1), '/', n)\n",
    "        log_prob = 0\n",
    "        # Calculate the probability of each bigram\n",
    "        for j in range(len(tokens) - 1):\n",
    "            prob = model.calc_prob(tokens[j], tokens[j + 1])\n",
    "            if prob == 0:\n",
    "                prob = 1e-5  # handle zero probabilities\n",
    "            log_prob += np.log(prob)\n",
    "            n_words += 1\n",
    "        log_probs += log_prob\n",
    "\n",
    "    # Calculate the final perplexity\n",
    "    avg_log_prob = log_probs / n_words\n",
    "    perplexity = np.exp(-avg_log_prob)\n",
    "    print('\\n')\n",
    "    \n",
    "    return perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1a96f66b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating perplexity: 3352 / 3352\n",
      "\n",
      "The perplexity of Bigram is: 325.8354\n"
     ]
    }
   ],
   "source": [
    "bigram = BiGram(unigram_count, bigram_count)\n",
    "\n",
    "# Perplexity\n",
    "bigram_perplexity = perplexity(bigram, valid_token_ids)\n",
    "print(f'The perplexity of Bigram is: {bigram_perplexity:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "520e6dc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating perplexity: 3352 / 3352\n",
      "\n",
      "The perplexity of Good Turing is: 130.5334\n"
     ]
    }
   ],
   "source": [
    "gt = GoodTuring(unigram_count, bigram_count, threshold=100)\n",
    "\n",
    "# Perplexity\n",
    "gt_perplexity = perplexity(gt, valid_token_ids)\n",
    "print(f'The perplexity of Good Turing is: {gt_perplexity:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0792a8fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating perplexity: 3352 / 3352\n",
      "\n",
      "The perplexity of Kneser-Ney is: 62.5943\n"
     ]
    }
   ],
   "source": [
    "kn = KneserNey(unigram_count, bigram_count, d=0.75)\n",
    "\n",
    "# Perplexity\n",
    "kn_perplexity = perplexity(kn, valid_token_ids)\n",
    "print(f'The perplexity of Kneser-Ney is: {kn_perplexity:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "41c59a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model: 'BiGram', w1: int, vocab_size: int):\n",
    "    \"\"\" Predict the w2 with the hightest probability given w1\n",
    "    \n",
    "    Args:\n",
    "        model: A BiGram, GoodTuring, or KneserNey model that has the calc_prob function\n",
    "        w1: current word\n",
    "        vocab_size: the number of tokens in the vocabulary\n",
    "    \"\"\"\n",
    "    result = None\n",
    "    highest_prob = 0\n",
    "    #start your code\n",
    "    for w2 in range(1, vocab_size):\n",
    "        prob = model.calc_prob(w1, w2)\n",
    "        if prob > highest_prob:\n",
    "            highest_prob = prob\n",
    "            result = w2\n",
    "        # End\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dc6fdb17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sharply falling stock prices do reduce consumer wealth damage business ____\n",
      "predicted last token: </s>\n",
      "---------------------------------------------\n",
      "but robert an official of the association said no ____\n",
      "predicted last token: longer\n",
      "---------------------------------------------\n",
      "it also has interests in military electronics and marine ____\n",
      "predicted last token: s\n",
      "---------------------------------------------\n",
      "first chicago since n has reduced its loans to such ____\n",
      "predicted last token: as\n",
      "---------------------------------------------\n",
      "david m jones vice president at g ____\n",
      "predicted last token: s\n",
      "---------------------------------------------\n",
      "the n stock specialist firms on the big board floor ____\n",
      "predicted last token: traders\n",
      "---------------------------------------------\n",
      "at the same time the business was hurt by ____\n",
      "predicted last token: the\n",
      "---------------------------------------------\n",
      "salomon will cover the warrants by buying sufficient shares or ____\n",
      "predicted last token: n\n",
      "---------------------------------------------\n",
      "in july southmark corp the dallas based real estate and financial ____\n",
      "predicted last token: officer\n",
      "---------------------------------------------\n",
      "he concluded his remarks by and at some ____\n",
      "predicted last token: of\n",
      "---------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(12345)\n",
    "\n",
    "vocab_size = len(tokenizer)\n",
    "indexes = np.random.choice(len(test_token_ids), 10, replace=False)\n",
    "for i in indexes:\n",
    "    token_ids = test_token_ids[i][1:-1]\n",
    "    print(' '.join([tokenizer.inverse_vocab[token_id] for token_id in token_ids]) + ' ____')\n",
    "    pred = predict(gt, token_ids[-1], vocab_size)\n",
    "    print(f'predicted last token: {tokenizer.inverse_vocab[pred]}')\n",
    "    print('---------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "866f8493",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_label(token_ids: List[List[int]], window_size: int=-1):\n",
    "    \"\"\" Split features and labels for the training, validation, and test datasets.\n",
    "    \n",
    "    Note:\n",
    "        If window size is -1, for a sentence with n tokens,\n",
    "            it selects the tokens rangeing from [0, n - 1) as the feature,\n",
    "            and selects tokens ranging from [1, n) as the label.\n",
    "        Otherwise, it divides a sentence with multiple windows and do the previous split.\n",
    "    \"\"\"\n",
    "    x = []\n",
    "    y = []\n",
    "    seq_lens = []\n",
    "    for sent_token_ids in token_ids:\n",
    "        if window_size == -1:\n",
    "            x.append(sent_token_ids[:-1])\n",
    "            y.append(sent_token_ids[1:])\n",
    "            seq_lens.append(len(sent_token_ids) - 1)\n",
    "        else:\n",
    "            if len(sent_token_ids) > window_size:\n",
    "                sub_sent_size = window_size + 1\n",
    "                n_window = len(sent_token_ids) // (sub_sent_size)\n",
    "                for i in range(n_window):\n",
    "                    start = i * sub_sent_size\n",
    "                    sub_sent = sent_token_ids[start:(start + sub_sent_size)]\n",
    "                    x.append(sub_sent[:-1])\n",
    "                    y.append(sub_sent[1:])\n",
    "                    seq_lens.append(len(sub_sent) - 1)\n",
    "                if len(sent_token_ids) % sub_sent_size > 0:\n",
    "                    sub_sent = sent_token_ids[-sub_sent_size:]\n",
    "                    x.append(sub_sent[:-1])\n",
    "                    y.append(sub_sent[1:])\n",
    "                    seq_lens.append(len(sub_sent) - 1)\n",
    "            else:\n",
    "                x.append(sent_token_ids[:-1])\n",
    "                y.append(sent_token_ids[1:])\n",
    "                seq_lens.append(len(sent_token_ids) - 1)\n",
    "    return x, y, seq_lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4f41134d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 68 68\n"
     ]
    }
   ],
   "source": [
    "window_size = 40\n",
    "x_train, y_train, train_seq_lens = get_feature_label(train_token_ids, window_size)\n",
    "x_valid, y_valid, valid_seq_lens = get_feature_label(valid_token_ids)\n",
    "x_test, y_test, test_seq_lens = get_feature_label(valid_token_ids)\n",
    "print(max(train_seq_lens), max(valid_seq_lens), max(test_seq_lens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9e1dbb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_batch(x_batch: List[List[int]], y_batch: List[List[int]], seq_lens_batch: List[int], pad_val: int):\n",
    "    \"\"\" Pad the sentences in a batch with pad_val based on the longest sentence.\n",
    "    \n",
    "    Args:\n",
    "        x_batch, y_batch, seq_lens_batch: the input data\n",
    "        pad_val: the padding value you need to fill to pad the sentences to the longest sentence.\n",
    "        \n",
    "    Return:\n",
    "        x_batch: Tensor, (batch_size x max_seq_len)\n",
    "        y_batch: Tensor, (batch_size x max_seq_len)\n",
    "        seq_lens_batch: Tensor, (batch_size, )\n",
    "    \"\"\"\n",
    "    max_len = max(seq_lens_batch)\n",
    "    # Start your code here\n",
    "    # Padding\n",
    "    x_batch = [sentence + [pad_val] * (max_len - len(sentence)) for sentence in x_batch]\n",
    "    y_batch = [sentence + [pad_val] * (max_len - len(sentence)) for sentence in y_batch]\n",
    "    # End\n",
    "    x_batch, y_batch = tf.convert_to_tensor(x_batch, dtype=tf.int64), tf.convert_to_tensor(y_batch, dtype=tf.int64)\n",
    "    seq_lens_batch = tf.convert_to_tensor(seq_lens_batch, dtype=tf.int64)\n",
    "    return x_batch, y_batch, seq_lens_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d52c7d7",
   "metadata": {},
   "source": [
    "###  RNN language model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c93ff407",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense\n",
    "from typing import Tuple\n",
    "\n",
    "class RNN(Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_units):\n",
    "        \"\"\" Init of the RNN model\n",
    "        \n",
    "        Args:\n",
    "            vocab_size, embedding_dim: used for initialze the embedding layer.\n",
    "            hidden_units: number of hidden units of the RNN layer.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        # Start your code here\n",
    "        self.embedding = Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = LSTM(hidden_units, return_sequences=True)\n",
    "        self.dense = Dense(vocab_size)\n",
    "\n",
    "        # End\n",
    "        \n",
    "    def call(self, x):\n",
    "        \"\"\" Forward of the RNN model\n",
    "        \n",
    "        Args:\n",
    "            x: Tensor, (batch_size x max_seq_len). Input tokens. Here, max_seq_len is the longest length of sentences in this batch becasue we did pad_batch.\n",
    "        Return:\n",
    "            outputs: Tensor, (batch_size x max_seq_len x vocab_size). Logits for every time step. !!!NO SOFTMAX HERE!!!\n",
    "        \"\"\"\n",
    "        # Start your code here\n",
    "        x = self.embedding(x)\n",
    "        outputs = self.lstm(x)\n",
    "        outputs = self.dense(outputs)\n",
    "        # End\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc15c14c",
   "metadata": {},
   "source": [
    "### Seq2seq loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4b6ca6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "## deprecated\n",
    "\n",
    "#from tensorflow_addon.seq2seq import sequence_loss\n",
    "# def seq2seq_loss(logits, target, seq_lens):\n",
    "#     \"\"\"\n",
    "#     Args:\n",
    "#         logits: Tensor (batch_size x max_seq_len x vocab_size). The output of the RNN model.\n",
    "#         target: Tensor (batch_size x max_seq_len). The groud-truth of words.\n",
    "#         seq_lens: Tensor (batch_size, ). The real sequence length before padding.\n",
    "#     \"\"\"\n",
    "#     loss = 0\n",
    "#     mask = tf.sequence_mask(seq_lens, dtype=tf.float32)\n",
    "#     loss = sequence_loss(logits, target, weights=mask)\n",
    "#     return loss\n",
    "\n",
    "def seq2seq_loss(logits, targets, seq_lens):\n",
    "    \"\"\"\n",
    "    Custom implementation of sequence loss for handling sequence-to-sequence models.\n",
    "\n",
    "    Args:\n",
    "        logits: Tensor of shape (batch_size, max_seq_len, vocab_size) containing the logits.\n",
    "        targets: Tensor of shape (batch_size, max_seq_len) containing the ground truth labels.\n",
    "        seq_lens: Tensor of shape (batch_size,) containing the real lengths of each sequence.\n",
    "\n",
    "    Returns:\n",
    "        A scalar tensor containing the average loss per batch, considering only the real sequence lengths.\n",
    "    \"\"\"\n",
    "    # Computing the cross entropy loss\n",
    "    loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=targets, logits=logits)\n",
    "    \n",
    "    # Creating a mask for padding positions\n",
    "    mask = tf.sequence_mask(lengths=seq_lens, maxlen=tf.shape(targets)[1], dtype=tf.float32)\n",
    "    \n",
    "    # Applying the mask to the loss\n",
    "    masked_loss = loss * mask\n",
    "    \n",
    "    # Calculating the average loss over all batches\n",
    "    loss_sum = tf.reduce_sum(masked_loss)\n",
    "    total_elements = tf.reduce_sum(mask)\n",
    "    average_loss = loss_sum / total_elements\n",
    "    \n",
    "    return average_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1c44ce4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(tokenizer)\n",
    "hidden_units = 256\n",
    "embedding_dim = 512\n",
    "num_epoch = 10\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7becf768",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNN(vocab_size, embedding_dim, hidden_units)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75966716",
   "metadata": {},
   "source": [
    "### Training RNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "24d69f62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 10 - Step 677 / 677 - train loss: 6.4266 - valid loss: 5.9178\n",
      "Epoch 2 / 10 - Step 677 / 677 - train loss: 5.7559 - valid loss: 5.5953\n",
      "Epoch 3 / 10 - Step 677 / 677 - train loss: 5.4572 - valid loss: 5.4244\n",
      "Epoch 4 / 10 - Step 677 / 677 - train loss: 5.2477 - valid loss: 5.3129\n",
      "Epoch 5 / 10 - Step 677 / 677 - train loss: 5.0824 - valid loss: 5.2377\n",
      "Epoch 6 / 10 - Step 677 / 677 - train loss: 4.9441 - valid loss: 5.1845\n",
      "Epoch 7 / 10 - Step 677 / 677 - train loss: 4.8225 - valid loss: 5.1491\n",
      "Epoch 8 / 10 - Step 677 / 677 - train loss: 4.7121 - valid loss: 5.1264\n",
      "Epoch 9 / 10 - Step 677 / 677 - train loss: 4.6099 - valid loss: 5.1142\n",
      "Epoch 10 / 10 - Step 677 / 677 - train loss: 4.5146 - valid loss: 5.1113\n"
     ]
    }
   ],
   "source": [
    "num_samples = len(x_train)\n",
    "n_batch = int(np.ceil(num_samples / batch_size))\n",
    "n_valid_batch = int(np.ceil(len(x_valid) / batch_size))\n",
    "for epoch in range(num_epoch):\n",
    "    epoch_loss = 0.0\n",
    "    for batch_idx in range(n_batch):\n",
    "        start = batch_idx * batch_size\n",
    "        end = start + batch_size\n",
    "        x_batch, y_batch, seq_lens_batch = x_train[start:end], y_train[start:end], train_seq_lens[start:end]\n",
    "        real_batch_size = len(x_batch)\n",
    "        x_batch, y_batch, seq_lens_batch = pad_batch(x_batch, y_batch, seq_lens_batch, pad_val=tokenizer.pad_token_id)\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            output = model(x_batch)\n",
    "            loss = seq2seq_loss(output, y_batch, seq_lens_batch)\n",
    "\n",
    "        if batch_idx % 1 == 0 or batch_idx == num_samples - 1:\n",
    "            print_line(f'Epoch {epoch + 1} / {num_epoch} - Step {batch_idx + 1} / {n_batch} - loss: {loss:.4f}')\n",
    "            \n",
    "        trainable_vars = model.trainable_variables\n",
    "        gradients = tape.gradient(loss, trainable_vars)\n",
    "\n",
    "        # Update weights\n",
    "        optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
    "        epoch_loss += loss * real_batch_size\n",
    "    \n",
    "    valid_loss = 0.0\n",
    "    for batch_idx in range(n_valid_batch):\n",
    "        start = batch_idx * batch_size\n",
    "        end = start + batch_size\n",
    "        x_batch, y_batch, seq_lens_batch = x_valid[start:end], y_valid[start:end], valid_seq_lens[start:end]\n",
    "        real_batch_size = len(x_batch)\n",
    "        x_batch, y_batch, seq_lens_batch = pad_batch(x_batch, y_batch, seq_lens_batch, pad_val=tokenizer.pad_token_id)\n",
    "        output = model(x_batch)\n",
    "        loss = seq2seq_loss(output, y_batch, seq_lens_batch)\n",
    "\n",
    "        if batch_idx % 1 == 0 or batch_idx == len(x_valid) - 1:\n",
    "            print_line(f'Epoch {epoch + 1} / {num_epoch} - Step {batch_idx + 1} / {n_valid_batch} - loss: {loss:.4f}')\n",
    "\n",
    "        valid_loss += loss * real_batch_size\n",
    "    print(f'\\rEpoch {epoch + 1} / {num_epoch} - Step {n_batch} / {n_batch} - train loss: {epoch_loss / num_samples:.4f} - valid loss: {valid_loss / len(x_valid):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8569eea4",
   "metadata": {},
   "source": [
    "### Perplexity of RNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e51db1d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating perplexity: 1 / 3352"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "cannot compute Mul as input #1(zero-based) was expected to be a float tensor but is a int32 tensor [Op:Mul]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[55], line 18\u001b[0m\n\u001b[0;32m     16\u001b[0m         n_words \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     17\u001b[0m     loss \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mreduce_mean(tf\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39msparse_softmax_cross_entropy_with_logits(labels\u001b[38;5;241m=\u001b[39my_line, logits\u001b[38;5;241m=\u001b[39moutput))\n\u001b[1;32m---> 18\u001b[0m     total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_line\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     20\u001b[0m perplexity \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m ((\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m/\u001b[39m n_words) \u001b[38;5;241m*\u001b[39m log_probs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\framework\\ops.py:7209\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   7207\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name):\n\u001b[0;32m   7208\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 7209\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: cannot compute Mul as input #1(zero-based) was expected to be a float tensor but is a int32 tensor [Op:Mul]"
     ]
    }
   ],
   "source": [
    "n = len(x_valid)\n",
    "log_probs = 0\n",
    "n_words = 0  # number of words to predict in the entire dataset\n",
    "total_loss = 0  # total loss of each word's loss\n",
    "for i in range(n):\n",
    "    if i % 1 == 0 or i == n - 1:\n",
    "        print_line('Calculating perplexity:', (i + 1), '/', n)\n",
    "    x_line, y_line, line_seq_lens = x_valid[i:i + 1], y_valid[i: i + 1], valid_seq_lens[i:i + 1]\n",
    "    x_line, y_line, line_seq_lens = pad_batch(x_line, y_line, line_seq_lens, tokenizer.pad_token_id)\n",
    "    output = model(x_line)\n",
    "    pred_probs = tf.nn.softmax(output, axis=-1)\n",
    "\n",
    "    for real_token, probs in zip(y_line[0], pred_probs[0]):\n",
    "        log_prob = tf.math.log(tf.clip_by_value(probs[real_token], 1e-9, 1.0))\n",
    "        log_probs += log_prob\n",
    "        n_words += 1\n",
    "    loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y_line, logits=output))\n",
    "    total_loss += loss * tf.size(y_line[0])\n",
    "print('\\n')\n",
    "perplexity = 2 ** ((-1 / n_words) * log_probs)\n",
    "print(f'Perplexity by definition: {perplexity:.4f}, Perplexity by loss: {np.exp(total_loss / n_words):.4f}')\n",
    "\n",
    "# If you implement correctly, the two perplexity will be almost the same."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3622689",
   "metadata": {},
   "source": [
    "###  Predicting the next word given a previous sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a3ad49",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(12345)\n",
    "\n",
    "vocab_size = len(tokenizer)\n",
    "indexes = np.random.choice(len(test_token_ids), 10, replace=False)\n",
    "for i in indexes:\n",
    "    token_ids = test_token_ids[i][1:-1]\n",
    "    print(' '.join([tokenizer.inverse_vocab[token_id] for token_id in token_ids]) + ' ____')\n",
    "    x = tf.convert_to_tensor(token_ids, dtype=tf.int64)  # now x is a tensor of (seq_len, )\n",
    "    # Start your code here\n",
    "\n",
    "\n",
    "    # End\n",
    "    print(f'predicted last token: {tokenizer.inverse_vocab[pred]}')\n",
    "    print('---------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a900292",
   "metadata": {},
   "source": [
    "Briefly analyze the result of N-Gram and RNN"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "CS584A_21F_Assignment3_sol.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "033f5d5d7d254e0eaa9e8248a922cd24": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_23bf828777d6427ca881362636957c1f",
       "IPY_MODEL_1d29f3408a014f69a7e5d422012af3df",
       "IPY_MODEL_79f0039ff69d442fb308d2572e45568e"
      ],
      "layout": "IPY_MODEL_777e888395634af98a54350e9afd3173"
     }
    },
    "04b88d3a05db465097d3b6d132b9d4d9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "08888abc179e4f4db80b340adf3cefc4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0afd68d6cc3e452b9995c16b45498e0c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1282ffc696e94bde9d464c086bf56a9e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1c400992df144367acc8f1684428f24e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1d29f3408a014f69a7e5d422012af3df": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dcf4e8ce928244b8b4c07ffe0225fffc",
      "max": 72,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5835dc4965724bb29c0f844c1de605a7",
      "value": 72
     }
    },
    "1e5cbadd09154cae8aa3ed9cffccaecf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1f3cad8f4790440991d8689a6901092b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_eef62927dca744b0b0ac405a69077e1d",
      "placeholder": "​",
      "style": "IPY_MODEL_3348deeabd834cc8af78d259c5d264eb",
      "value": "good turing: 100%"
     }
    },
    "22fce55c7fac47be8151cf2aabb19c7e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "232b015d2d50456199173cf15c705f76": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9fa143b50b4a4071966a75797331120c",
       "IPY_MODEL_4fc66537350d420b98eeda74530956e8",
       "IPY_MODEL_b508585491914913af1e97442d173c19"
      ],
      "layout": "IPY_MODEL_ec79cb6402fb48209b04cf141b682e02"
     }
    },
    "23bf828777d6427ca881362636957c1f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_486338a06f9740ddae037dc655a7d18a",
      "placeholder": "​",
      "style": "IPY_MODEL_d1c4dda64d4d4938ac0592eede0af27a",
      "value": "Evaluating: 100%"
     }
    },
    "28977ef615ed4798abeed10e8f8d3677": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3348deeabd834cc8af78d259c5d264eb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3545d285dd56410eb867b6bddd64bbfb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_798c1eca83ef4409ad5cf05ead9a55c0",
      "placeholder": "​",
      "style": "IPY_MODEL_589fdc916f904eb8a2c14cde025eee02",
      "value": " 3370/3370 [00:22&lt;00:00, 148.03it/s]"
     }
    },
    "366a68482f1b4c9aace014294204a3d4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3f98bb7355c8445c8e6f533c010723df": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_554d18a1a4d846b184aa00cbc93a5578",
      "placeholder": "​",
      "style": "IPY_MODEL_1c400992df144367acc8f1684428f24e",
      "value": "perplexity: 100%"
     }
    },
    "43ee7b41140e428ba38e051926a185e5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "486338a06f9740ddae037dc655a7d18a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4fc66537350d420b98eeda74530956e8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_22fce55c7fac47be8151cf2aabb19c7e",
      "max": 920,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_43ee7b41140e428ba38e051926a185e5",
      "value": 27
     }
    },
    "546564a20a2243c1a901562e6e16357e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "554d18a1a4d846b184aa00cbc93a5578": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5835dc4965724bb29c0f844c1de605a7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "589fdc916f904eb8a2c14cde025eee02": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5eac3a9da9574e898c0c10b93577b244": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "61d7f90ab5d140c48dc3dd199b6acf75": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "634379b2174944c6a2527d43d6fb21ca": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "661ea4ef6e4c46e4930a9fe6622e15b6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "6be04f4c233d468595cad6b45aff8040": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6f013dd9434e4a019af0ffcaf5bc1194": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f4927eb77cee4fc69c897fb3911f5793",
      "placeholder": "​",
      "style": "IPY_MODEL_ceb86bd353e44e358ade1af7dd367b1a",
      "value": "100%"
     }
    },
    "728ff942c62e4316bee3712f83be0d4f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "73800733b6e549f08c2dc81b292520c4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "73887cb869e94589b4e5b1b691b6f937": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_28977ef615ed4798abeed10e8f8d3677",
      "max": 42068,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8e5a920068fd48b6b7af469c6e43b2f4",
      "value": 42068
     }
    },
    "75ad4c14843d41a18298b4580ac79663": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_aa61fe57992243f581ae3a2be486164c",
      "max": 42068,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0afd68d6cc3e452b9995c16b45498e0c",
      "value": 42068
     }
    },
    "76435fd43d15403aa6ae09c170d08bff": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "777e888395634af98a54350e9afd3173": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "798c1eca83ef4409ad5cf05ead9a55c0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "79f0039ff69d442fb308d2572e45568e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_73800733b6e549f08c2dc81b292520c4",
      "placeholder": "​",
      "style": "IPY_MODEL_e469615a3ad143318cec11ed6ea82346",
      "value": " 72/72 [00:19&lt;00:00,  3.62it/s]"
     }
    },
    "7e51e710fe314164bd358efa9f7c553e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "7f5cad4515454ac1b3cf13bafe2be8b7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_76435fd43d15403aa6ae09c170d08bff",
      "max": 42068,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_661ea4ef6e4c46e4930a9fe6622e15b6",
      "value": 42068
     }
    },
    "82188772d1a64ddfbf2b18049e8991f0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8e5a920068fd48b6b7af469c6e43b2f4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "92d196ac95b34d0a9b85fde8c291c863": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "93d68d9d5ae64d3cb21e70b9e60dad35": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "96df479f4bce49a6ad50823ca13c7a8a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9a53da36e76a4c078ec997f7ecb19c53": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1f3cad8f4790440991d8689a6901092b",
       "IPY_MODEL_7f5cad4515454ac1b3cf13bafe2be8b7",
       "IPY_MODEL_dcf79d8ac613425fa5680359fcd55e52"
      ],
      "layout": "IPY_MODEL_96df479f4bce49a6ad50823ca13c7a8a"
     }
    },
    "9a8be20f7afd48a38aaaac982a3e020b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9e3a4277f4ff40078f28d3a0abee11c1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9fa143b50b4a4071966a75797331120c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_04b88d3a05db465097d3b6d132b9d4d9",
      "placeholder": "​",
      "style": "IPY_MODEL_366a68482f1b4c9aace014294204a3d4",
      "value": "Traning at epoch 0:   3%"
     }
    },
    "a83a2f6476014b699354aeec51081856": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "aa61fe57992243f581ae3a2be486164c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "aebb9ebcf3f642d1ab1cbdc27dc4765c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_08888abc179e4f4db80b340adf3cefc4",
      "max": 3370,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_7e51e710fe314164bd358efa9f7c553e",
      "value": 3370
     }
    },
    "b00b6b54679a43b3bdc1259ad6f0e8b0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_eeb84b4f6bea45a6bcadd12e6a68ee83",
       "IPY_MODEL_aebb9ebcf3f642d1ab1cbdc27dc4765c",
       "IPY_MODEL_da209ecaa8af40e6b771ec773a4596e4"
      ],
      "layout": "IPY_MODEL_d05c534b93d24537924364b5e0f90e41"
     }
    },
    "b2df758ccb7c4ce2ae4ace0d60567536": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b3518c5087a54b8e90271e5960d91865": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_728ff942c62e4316bee3712f83be0d4f",
      "placeholder": "​",
      "style": "IPY_MODEL_ffd343e5537b411e821e1c7d1b40fd57",
      "value": " 42068/42068 [04:51&lt;00:00, 146.97it/s]"
     }
    },
    "b508585491914913af1e97442d173c19": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1282ffc696e94bde9d464c086bf56a9e",
      "placeholder": "​",
      "style": "IPY_MODEL_9e3a4277f4ff40078f28d3a0abee11c1",
      "value": " 27/920 [00:07&lt;04:09,  3.59it/s]"
     }
    },
    "b86c1938fbf54e1f9ec838d22ac8e686": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c63c7845afb448adb5e2b791aa6711f2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3f98bb7355c8445c8e6f533c010723df",
       "IPY_MODEL_f7105aa135ab48fb8ba43a3b6df554a8",
       "IPY_MODEL_3545d285dd56410eb867b6bddd64bbfb"
      ],
      "layout": "IPY_MODEL_b86c1938fbf54e1f9ec838d22ac8e686"
     }
    },
    "c6971f8d9554424c90a42d04cbb42579": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_61d7f90ab5d140c48dc3dd199b6acf75",
      "placeholder": "​",
      "style": "IPY_MODEL_b2df758ccb7c4ce2ae4ace0d60567536",
      "value": "unigram counting: 100%"
     }
    },
    "ceb86bd353e44e358ade1af7dd367b1a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d05c534b93d24537924364b5e0f90e41": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d1c4dda64d4d4938ac0592eede0af27a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "da209ecaa8af40e6b771ec773a4596e4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_82188772d1a64ddfbf2b18049e8991f0",
      "placeholder": "​",
      "style": "IPY_MODEL_546564a20a2243c1a901562e6e16357e",
      "value": " 3370/3370 [00:23&lt;00:00, 150.49it/s]"
     }
    },
    "db92112fd1404654a3f11dec95a79378": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6f013dd9434e4a019af0ffcaf5bc1194",
       "IPY_MODEL_73887cb869e94589b4e5b1b691b6f937",
       "IPY_MODEL_e6f545c0008e45ff95ea610c86b10987"
      ],
      "layout": "IPY_MODEL_634379b2174944c6a2527d43d6fb21ca"
     }
    },
    "dcf4e8ce928244b8b4c07ffe0225fffc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dcf79d8ac613425fa5680359fcd55e52": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1e5cbadd09154cae8aa3ed9cffccaecf",
      "placeholder": "​",
      "style": "IPY_MODEL_5eac3a9da9574e898c0c10b93577b244",
      "value": " 42068/42068 [00:00&lt;00:00, 471213.73it/s]"
     }
    },
    "e469615a3ad143318cec11ed6ea82346": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e69bba41e3384f19be77eb2e870ac131": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c6971f8d9554424c90a42d04cbb42579",
       "IPY_MODEL_75ad4c14843d41a18298b4580ac79663",
       "IPY_MODEL_b3518c5087a54b8e90271e5960d91865"
      ],
      "layout": "IPY_MODEL_92d196ac95b34d0a9b85fde8c291c863"
     }
    },
    "e6f545c0008e45ff95ea610c86b10987": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6be04f4c233d468595cad6b45aff8040",
      "placeholder": "​",
      "style": "IPY_MODEL_e94ddfd39d1d4e80937eb1c7257b4526",
      "value": " 42068/42068 [04:49&lt;00:00, 148.55it/s]"
     }
    },
    "e94ddfd39d1d4e80937eb1c7257b4526": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ec79cb6402fb48209b04cf141b682e02": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "eeb84b4f6bea45a6bcadd12e6a68ee83": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9a8be20f7afd48a38aaaac982a3e020b",
      "placeholder": "​",
      "style": "IPY_MODEL_f7f1f75e05d34717ba63436a403541d4",
      "value": "perplexity: 100%"
     }
    },
    "eef62927dca744b0b0ac405a69077e1d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f4927eb77cee4fc69c897fb3911f5793": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f7105aa135ab48fb8ba43a3b6df554a8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a83a2f6476014b699354aeec51081856",
      "max": 3370,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_93d68d9d5ae64d3cb21e70b9e60dad35",
      "value": 3370
     }
    },
    "f7f1f75e05d34717ba63436a403541d4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ffd343e5537b411e821e1c7d1b40fd57": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
